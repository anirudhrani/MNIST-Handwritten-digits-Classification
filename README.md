# MNIST-Handwritten-digits-Classification-Using-KNN-

## Introduction
The MNIST dataset contains black and white images ofhandwritten disgits from 0 - 9. The dataset can be divided into two groups. A group of 60,000 for training the model and an additional 10,000 for testing. In here, I have used a module called input_data which originally can be found here:- https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/input_data.py. 


## The Nearest Neighbor Algorithm
The K-nearest neighbor (KNN) is a supervised learning algorithm for both classification or
regression. It is a system that assigns the class of the sample tested according to its distance
from the objects stored in the memory.
The distance, d, is defined as the Euclidean distance between two points.

The advantage of this method of classification is the ability to classify objects whose classes are not linearly separable. It is a stable classifier, given that small perturbations of the training data do not significantly affect the results obtained. The most obvious disadvantage, however, is that it does not provide a true mathematical model; instead, for every new classification, it should be carried out by adding the new data to all initial instances and repeating the calculation procedure for the selected K value.

### STEP 1 :- Building the training set.
### STEP 2 :- COST FUNCTION
### STEP 3 :- EVALUATION AND TESTING 







